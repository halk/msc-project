\chapter{Evaluation}

This chapter evaluates if the implemented solutions meet the objectives as specified in section \ref{intro-objectives}. It further discusses their limitations and potential weaknesses.

\section{Integration Framework}
\label{evaluation-framework}

Generally speaking, the resulting solution for the integration framework meets the objectives set in section \ref{intro-objectives-framework}. These objectives are discussed individually in the following sections.

\subsubsection{Multi-Purposeness}
\label{evaluation-framework-multipurposeness}

Being part of the project title, this is a characterising property of the framework and signifies that the framework should cope with different kind of data as well as recommendation techniques. It can be seen as achieved for the following reasons: First, an implemented recommender engine is successfully used for more than one recommender use-case. The recommenders \emph{viewed_products} and \emph{wishlisted_products} are using the \emph{In-Common} recommender engine.

Second, as an outcome of the work discussed in \ref{evaluation-engines}, the framework already accomodates two completely distinct recommender techniques, namely \emph{collaborative} and \emph{content-based filtering}. Also, the recommenders using these recommender engines are providing different kind of data (user behaviour and item features).

Third, the same installation of the framework and its configured recommenders can be used by more than one domain application which may have independent purposes. Although this is true both by design and implementation, it could not be verified due to the lack of a second demo domain application.

\subsubsection{Ease of Integration}

This section evaluates the ease of integration of both domain application and recommender engines. As far as the domain application is concerned, the event-based integration provided a light-weight approach. In fact, with the exploitation of object-oriented principles, the footprint of source code handling events and recommendations were in some cases as small as six lines of code and an XML entry (Figure \ref{fig:evaluation-framework-easy-magento}). The interaction with the framework itself is identical regardless of recommender engine and thus has been centralised in a client class.

\begin{figure}[ht]
    \inputminted{php}{./includes/source/demo/app/code/Koklu/Event/Model/Observer/Customer/Wishlist/Add.php}
    \begin{minted}{xml}
<?xml version="1.0"?>
<config xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:noNamespaceSchemaLocation="[...]/lib/internal/Magento/Framework/Event/etc/events.xsd">
    <!-- [...] -->
    <event name="wishlist_add_product">
        <observer name="recommender_event" instance="Koklu\Event\Model\Observer\Customer\Wishlist\Add" method="process" />
    </event>
    <!-- [...] -->
</config>

    \end{minted}
    \caption{Magento Wishlist Event Handler (Code Listing)}
    \label{fig:evaluation-framework-easy-magento}
\end{figure}

On the recommender engine side, the evaluation is more difficult. The integration of the recommender engines, implemented as part of this project, were in reality straightforward (see Figure \ref{fig:implementation-framework-engine-adapter}). Being designed as services themselves, the engine adapters in the framework were thin clients making sure that the data passed through the taxonomy mapping and formatted in the way the engine expects. However, when an existing recommender engine is going to be integrated, which may have no \emph{application-programming interface (API)} or data persistence, the code footprint of the engine adapter may be more complex than the ones implemented in this project. Moreover, it may require changes on the recommender engine itself. For example, to utilise the item similarity capabilities of \emph{Apache Mahout}, a wrapper has to be implemented in Java which provides an API to the framework as well as a database to store item data in MySQL since Apache Mahout only supports MySQL tables and \emph{comma-separated value (CSV)} files. In summary, recommender engines, which provide interfaces or are explicitly designed to work with this framework, can capitalise on the ease of integration the most. It is yet still possible to integrate engines which do not meet this criteria with an additional effort.

\subsubsection{Encapsulation}

The concept of taxonomy proofed to be sufficient to isolate domain application and recommender engine terminologies as well as internals from each other. There has been no encapsulation issues which were not solvable by taxonomies in the duration of the project. Nevertheless, in case, they can be sorted out by the respective engine adapter as a final measure before the request is passed to the recommender engine.

Furthermore, the achievement of this objective allows specialised teams to work on either the domain application integration or the recommender engine in parallel as long as the taxonomy is identified.

\subsubsection{Reusability}

This objective is similar to multi-purposeness but emphasises the reusability of recommender engines and recommendations. As mentioned in section \ref{evaluation-framework-multipurposeness}, the recommenders \emph{viewed_products} and \emph{wishlisted_products} are using the \emph{In-Common} recommender engine. This was possible by slightly different taxonomies and without any auxiliary code in domain application, framework and recommendation engine.

Furthermore, hybrid recommenders completely rely on the recommendations of other recommenders. For example, the \emph{weighted} hybrid recommender successfully combines \emph{viewed_products} and \emph{wishlisted_products}.

\subsubsection{Technological Unbiasedness}

Thanks to the \emph{service-oriented architecture (SOA)}, framework and recommender engines were built as separate systems which allowed the usage of various technologies in this project. In fact, including the domain application -- yet excluding provisioning and secondary technologies such as \emph{XML} or \emph{CSV}, the project is composed of 3 programming languages, 3 database management and 1 message queue system.

\section{Recommender Engines}
\label{evaluation-engines}

\subsection{Collaborative Recommender Engine: In-Common}

The effort of implementing the collaborative recommender engine \emph{In-Common} has been felicitous. The fundamental idea of using a graphical database to represent behavioural patterns turned out to be working well. It works out-of-the-box and does not require any initial data migrations.

However, there is the substantial issue called \emph{cold start} which is a general problem of collaborative recommenders. Cold start refers to the scenario when there is no data about the given user and no recommendations to show yet. This engine currently returns an empty recommendation list, which is not ideal. A typical solution to this problem is a hybrid recommender which falls back to a content-based recommender engine when the collaborative recommender fails to deliver recommendations \cite{schein2002methods}.

\subsection{Content-Based Recommender Engine: Item-Similarity}

The \emph{Item-Similarity} recommender engine was implemented to evaluate if the framework is capable of handling a content-based recommendation engine in a data-agnostic and schema-less way. Although it served this objective well, it would be considered a poorly performing recommender engine for content-based filtering. This is due to two main issues:

First, the engine is not thread safe. When an item is added, the engine loops through all other items and calculates their similarity with the added item. After that, the item is persisted in the database. However, when there is another item concurrently added by the engine, then the item, which was being added first, is not in the database yet. Once both processes are completed, there would be no similarity score between these two new nodes. This would be for an indefinite time since there is no reprocessing happening unless one of the items is changed again.

Second, the similarity algorithm is very naive since all attributes are compared in their string representation only. It should support distance-based similarity as well as additional similarity functions by data type. Also, the engine lacks weighting as the similarity of certain attributes may have a higher meaning than others e.g. matching brand is far more relevant than a matching country of origin. Furthermore, some attributes may be hierarchical or categorical with specific distances between values e.g. \emph{grey} being closer to \emph{black} than \emph{green}.

\section{Integration Into Magento}
\label{evaluation-domain}

The integration of the framework into Magento was a straightforward experience. The source code footprint and complexity ended up being considerably low. A particular concern was the flexibility of managing product attributes to be considered for the content-based recommender engine as well as the performance of a complete export. The solution for the former was already discussed in section \ref{implementation-magento-masterdata}. The latter has been optimised by performing the export in batches and implementing the Event API of the framework asynchronously, resulting in 189 products being exported in 100 seconds.

Finally, the sample data generator of Magento has been a challenge throughout the duration of this project. Initially, it was planned to use the performance tool kit which generates hundred thousands of products in order to run performance tests. However, it turned out that it creates products with the same but numbered attribute data such as \emph{Product \#1} which is not a good basis to validate an engine computing similarity. The sample data generator on the other hand creates product with meaningful data. Nevertheless, the generator was tremendously slow taking more than half of a day, if it completes successfully at all. Additionally, the number of products created by the generator were just 189 visible products.