\chapter{Implementation \& Testing}

This chapter not only discusses the technological details of this project but also introduces concrete implementations of two recommender engines as well as one domain system.

From the very start of this project, it was planned to use free and open-source technologies -- from database management systems to re-usable software libraries. Beside being a well-established best practice in the software programming, the main motivation for this is to avoid software code which is trivial and not contributing to the objectives of the project. It would have gone beyond the scope of this project to build everything from scratch. In fact, by using open-source technology the resulting software code has become very compact and readable.

\section{Framework}

The framework has been written in \emph{Python} and is entirely object-oriented. The source code is grouped into modules. The directory structure is as follows:

\begin{description}
    \item[api] implements the \emph{application programming interface (API)}.
    \item[config] holds the configuration file as well as the XML schema definition.
    \item[core] provides classes processing the configuration file as well as taxonomies. Furthermore, the engine submodule implements abstract base classes for engine adapters.
    \item[engines] contains engine adapter classes. In this case, it has adapters for the engines \emph{in-common}, \emph{item-similarity} and the hybrid engine \emph{weighted}.
    \item[log] has log files which are useful to troubleshoot problems.
    \item[tests] defines a unit test suite.
    \item[worker] implements the workers for Event and Recommend
    \item[api.wsgi] is the WSGI server loaded by Apache and runs the API.
    \item[config.py] loads the configuration and makes it available for other classes in the source code.
    \item[monitor.py] reloads the WSGI server when local changes to Python files were detected. The author of this particular file has been acknowledged in the source code.
    \item[requirements.txt] holds the name and versions of Python libraries the framework is depending on. It is used by the Python dependency manager \emph{pip}.
\end{description}

The framework has no persistence at all and thus does not utilise a database management system. As mentioned in the section \ref{architecture-framework}, it operates as middleware between domain and recommender engines, therefore relying on those to handle their persistence requirements. as far as the framework is concerned, there is no need or purpose to persist data.

\subsection{API}

The \emph{application programming interface (API)} of the framework is based on the popular, so-called micro web application framework \emph{Flask}. The notation of micro refers to the fact, that Flask is very minimal and has almost no constraints on other technologies such as database management systems.

Although Flask is RESTful compliant by default, the Flask extension \emph{Flask-RESTful} was used in this project. Where Flask associates a call back to a route such as \texttt{/event}, Flask-RESTful associates a resource class and method e.g. Event and \emph{post} to the route (Figure \ref{fig:implementation-framework-api-event}).

\begin{figure}[ht]
    \inputminted{py}{./includes/source/framework/api/event.py}
    \caption{Event API Code Listing}
    \label{fig:implementation-framework-api-event}
\end{figure}

Additionally, the API makes use of the \emph{Blueprint} feature of Flask which allows the implementation of independent APIs and its subscription to the main API with a prefix (Figure \ref{fig:implementation-framework-api}).

\begin{figure}[ht!]
    \begin{minted}{python}
from flask import Flask
from config import config

# setting up flask
app = Flask(__name__)
celery = config.get_celery('worker')

# setting up logging
# [...]

# registering submodules
from api.event import event
from api.recommend import recommend

app.register_blueprint(event, url_prefix='/event')
app.register_blueprint(recommend, url_prefix='/recommend')

# default route

@app.route("/")
def hello():
    return "Welcome to the Multi-Purpose Recommender Framework!"
    \end{minted}
    \caption{API Code Listing}
    \label{fig:implementation-framework-api}
\end{figure}

The API uses the \emph{JavaScript Object Notation (JSON)} format data and is served by the open-source web server \emph{Apache} as a virtual host through the \emph{web server gateway interface (WSGI)} and listens to requests at \href{http://api.msc.koklu.me}{\texttt{api.msc.koklu.me}}.

It was originally proposed to use \emph{NodeJS} and \emph{express} for the API. However it was chosen to use Python for the following reasons. First, the rest of the framework was going to be in Python and the task queue management software \emph{Celery}, which is going to be introduced in the next section, is working most elegantly with Python. Second, there was no exclusive benefit by implementing the API in NodeJS. Third, Flask provides the same minimalistic approach to defining routes as express.

\subsection{Worker \& Task Queue}

The project relies on the task queue \emph{Celery} to establish an asynchronous and selectively synchronous communication between the API and workers. Celery is written in Python and supports multiple brokers such as \emph{RabbitMQ} and \emph{Beanstalk}. Former is used as broker in this project. The Event API is calling its worker asynchronously -- thus not waiting for a response (queue \& forget) -- whereas the Recommend API is doing that synchronously. Figure \ref{fig:implementation-framework-worker} lists the source code of the event worker which is upon request going through all observers subscribed to the given event and calls the configured event method on the engine adapter.

\begin{figure}[ht]
    \inputminted{py}{./includes/source/framework/worker/event.py}
    \caption{Event Worker Code Listing}
    \label{fig:implementation-framework-worker}
\end{figure}

It was initially intended to use RabbitMQ natively as a message bus implementing the \emph{advanced message queuing protocol (AMQP)}. However, while looking for RabbitMQ client libraries and elegant ways to manage the overhead of using message buses for distributing tasks, Celery was discovered which abstracts that complexity completely. Tasks can be run as if they are a regular method in the source code (see Figure \ref{fig:implementation-framework-api-event}).

Flower is an administrative interface for Celery providing a real-time monitor and can be accessed at \href{http://flower.msc.koklu.me}{\texttt{flower.msc.koklu.me}} (Figure \ref{fig:implementation-framework-flower}).

\begin{figure}[ht]
    \includegraphics[width=\textwidth,center]{screens/flower.png}
    \caption{Flower for Celery (Screenshot)}
    \label{fig:implementation-framework-flower}
\end{figure}

\subsection{Configuration}

\begin{figure}[ht!]
    \begin{minted}{xml}
<?xml version="1.0" encoding="UTF-8"?>
<config xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:noNamespaceSchemaLocation="./config.xsd">
    <recommenders>
        <!-- [...] -->
        <recommender name="similar_products_in_basket" engine="item_similarity">
            <on event="saved_product" do="post" />
            <on event="deleted_product" do="delete" />
            <taxonomy inherit="base">
                <taxon name="item_id">sku</taxon>
                <taxon name="itemIds">sku</taxon>
                <taxon name="attributes">data</taxon>
            </taxonomy>
        </recommender>
        <hybrid_recommender name="interesting_products" engine="weighted">
            <components>
                <component name="views" recommender="common_products_viewed" />
                <component name="wishlists" recommender="common_products_wishlisted" />
            </components>
            <settings>
                <weight>
                    <views>0.25</views>
                    <wishlists>0.75</wishlists>
                </weight>
            </settings>
        </hybrid_recommender>
    </recommenders>
    <taxonomies>
        <taxonomy name="base">
            <taxon name="limit">limit</taxon>
        </taxonomy>
        <!-- [...] -->
    </taxonomies>
    <engines>
        <engine name="in_common">
            <settings>
                <base_url>http://localhost:8080/</base_url>
            </settings>
        </engine>
        <!-- [...] -->
    </engines>
    <settings>
        <celery>
            <broker>amqp://framework:framework@localhost:5672/framework</broker>
            <backend>redis://localhost</backend>
        </celery>
    </settings>
</config>
    \end{minted}
    \caption{Shortened XML Configuration Code Listing}
    \label{fig:implementation-framework-configuration}
\end{figure}

Figure \ref{fig:implementation-framework-configuration} shows a shortened configuration file of the framework and is explained as follows:

\begin{description}
    \item[recommenders/recommender] defines a recommender by name and the engine to be used. Furthermore it has a list of events it subscribes to (\texttt{on}) where the \texttt{do} attribute refers to the method of the engine adapter to be called when the event occurs. A recommender also defines a taxonomy which usually inherits from a global taxonomy.
    \item[recommenders/hybrid_recommender] defines a hybrid recommender which consists of two or more components. It may also have some settings which can be accessed by the engine adapter.
    \item[taxonomies/taxonomoy] defines a global taxonomy which is a terminology mapper between domain and recommender engines. It may inherit from another taxonomy. A taxonomy consists of taxon elements which describe a single mapping.
    \item[engines/engine] holds settings for engines.
    \item[settings] hold global settings of the framework such as connection details for Celery.
\end{description}

The project also provides an \emph{XML schema definition (XSD)} which can be used to validate a framework configuration.

\subsection{Engine Adapters}
\label{implementation-framework-engine-adapter}

\emph{Engine adapters} are thin clients to recommender engines. The formal requirement is that they implement a \texttt{recommend} method as well as methods used in event subscriptions. Other than that it is completely flexible in how the engine is called. For convenience, the abstract base class provides a RESTful skeleton which is used by the engine adapters implemented in this project such as the \emph{item-similarity} adapter (see Figure \ref{fig:implementation-framework-engine-adapter}). Engine adapters have access to engine settings defined in the configuration file such as a \emph{uniform resource locator (URL)}.

\begin{figure}[!ht]
    \inputminted{py}{./includes/source/framework/engines/item\string_similarity.py}
    \caption{Item-Similarity Engine Adapter Code Listing}
    \label{fig:implementation-framework-engine-adapter}
\end{figure}

Engine adapters for hybrid engines are more than just thin clients. Their formal requirement is to implement a \texttt{recommend} method without any event methods. In this method they have full flexibility on how to make use of the components. Figure \ref{fig:implementation-framework-hybrid-engine-adapter} shows the implementation of the \emph{weighted} hybrid engine adapter.

\begin{figure}[!ht]
    \begin{minted}{py}
from collections import OrderedDict
from core.engine.hybrid import HybridEngine as ParentHybridEngine

class HybridEngine(ParentHybridEngine):
    def recommend(self, body):
        return self.merge(self.apply_weight(self.get_results(body)))

    def get_results(self, body):
        results = {}
        for name, component in self.components.iteritems():
            result = component.recommend(body, True)
            if result:
                results[name] = result

        return results

    # [...] implementations of merge and apply_weight
    \end{minted}
    \caption{Weighted Hybrid Engine Adapter Code Listing}
    \label{fig:implementation-framework-hybrid-engine-adapter}
\end{figure}

\subsection{Testing}

The implementation of the framework makes extensive use of automated \emph{unit tests}. Unit testing is a software testing method which validates the correctness and executability pieces of software code (\emph{units}) such as functions, methods and classes. In fact, the 39 unit tests provided have a code coverage of one hundred per cent which means that every line of code is passed during one or more unit tests. These unit tests are testing the API, the validity of the XML configuration, core classes, engine adapters as well as workers. A separate XML configuration file is also included which makes sure that some rarer edge cases are tested as well.

The project utilises \emph{nosetests} to run the tests. Furthermore, the \emph{Software as a Service (SaaS)} platform \emph{Travis CI} is used to build a virtual environment and call nosetests everytime the framework code has been changed (pushed into the \emph{GitHub} repository). This is also known as \emph{continuous integration (CI)}. Finally, the SaaS Scrutinizer is integrated to process the code coverage reports generated by Travis CI. The Travis CI reports can be found here: \href{https://travis-ci.org/halk/recowise}{\texttt{travis-ci.org/halk/recowise}}.

\section{Engines}

\subsection{Collaborative Recommender: In-Common}

This recommendation engine has a collaborative filtering approach and basically performs recommendations as shown in Figure \ref{fig:collaborative}: \emph{recommending items which other users, who have experienced the same items as the reference user, have experienced but the reference user has not yet}. The engine is processing events and recommendation requests real-time. Although it persists data, it is data-agnostic -- in other words knows how the data is structured but does not require knowledge about the data content.

The fundamental idea behind this engine is to parametise the aforementioned query. There are four parameters in this query: \emph{subject} such as a user or customer, \emph{object} such as a product or even basketball player, \emph{relationship} such as viewed or favourited and \emph{subject ID} such as the current or reference user. After putting the parameters in place the query is now: \emph{recommending OBJECT wich other SUBJECT, wo have RELATIONSHIP the same OBJECT as the SUBJECT ID, have RELATIONSHIP but the SUBJECT ID has not yet}.

This engine has been written in \emph{Go} -- a statically typed language developed at \emph{Google} in 2007. \citet{pike12} explains the motivation behind building Go:

\say{\emph{The goals of the Go project were to eliminate the slowness and clumsiness of software development at Google, and thereby to make the process more productive and scalable. The language was designed by and for people who write -- and read and debug and maintain -- large software systems.}}

As far as this project is concerned, there was much interest in using a statically typed, compiled language in one of its subprojects. The code is organised in packages as follows:

\begin{description}
    \item[api] implements the \emph{application programming interface (API)}.
    \item[engine] provides capabilities of the engine yet at the present time acts merely as an interface to the graph functions.
    \item[graph] performs operations and queries on the database.
    \item[log] holds log files for troubleshooting.
    \item[model] defines data models such as a recommendation request or relationship.
    \item[util] offers a few utility functions.
\end{description}

Go has out-of-the-box support for building a API documentation for Go source code. The documentation for the In-Common recommender engine can be found here: \href{http://godoc.org/github.com/halk/in-common}{\texttt{godoc.org/github.com/halk/in-common}}.

\subsubsection{API}

The API of this engine is built based on the \texttt{http} package of Go as well as the \texttt{gorilla} packages. The following services are available:

\begin{description}
    \item[POST /event] processes a new event and expects a JSON-encoded payload consisting of \emph{subject}, \emph{subject_id}, \emph{object}, \emph{object_id} and \emph{relationship}.
    \item[DELETE /event] deletes an event and expects the same JSON-encoded above.
    \item[GET /recommend] receives a recommendation request with \emph{subject}, \emph{subject_id}, \emph{object}, \emph{relationship} and \emph{limit} GET parameters but returns a JSON-encoded list of recommended \emph{object IDs}. The parameter \emph{limit} specifies how many recommendations should be queried and returned.
\end{description}

\subsubsection{Data Representation}

\begin{figure}[ht]
    \includegraphics[width=250pt,center]{implementation/incommon\string_nodes.pdf}
    \caption{In-Common Data Representation}
    \label{fig:implementation-incommon-nodes}
\end{figure}

The data representation is the heart of this engine. As proposed in the project proposal, the graphical database \emph{Neo4j} has been used as database management system. The graphical representation is ideal for events since they can be perceived as a relationship between two nodes -- subject and object (Figure \ref{fig:implementation-incommon-nodes}). Hence, the recommendation request is just a query against this graph (Figure \ref{fig:implementation-incommon-recommendation-query}).

\begin{figure}[!ht]
    \begin{minted}{go}
cq := neoism.CypherQuery{
    Statement: fmt.Sprintf(
        `
            MATCH (subject:%[1]s)-[:%[2]s]->(%[3]s)<-[:%[2]s]-(%[1]s)-[r:%[2]s]->(object:%[3]s)
            WHERE subject.id = {subjectId} AND NOT((subject)-[:%[2]s]->(object))
            RETURN object.id, COUNT(r) AS weight
            ORDER BY weight DESC
            LIMIT %[4]d
      `,
        util.UpperCaseFirst(rq.Subject), strings.ToUpper(rq.Relationship),
        util.UpperCaseFirst(rq.Object), rq.Limit,
    ),
    Parameters: neoism.Props{"subjectId": rq.SubjectID},
    Result:     &res,
}
    \end{minted}
    \caption{In-Common Recommendation Query Code Listing}
    \label{fig:implementation-incommon-recommendation-query}
\end{figure}

\subsubsection{Testing}

This engine has been tested with unit tests covering about 93 per cent of the source code. Similar to the framework, Travis CI is used to continuously run tests when changes to the source code are pushed to the repository. The Travis CI reports can be found here: \href{https://travis-ci.org/halk/in-common}{travis-ci.org/halk/in-common}.

\subsection{Content-Based Recommender: Item Similarity}

\emph{Status: Not Started}

\begin{itemize}
\item Content-based filtering
\item Silex, MongoDB, Doctrine ODM
\item Requires master data
\item Show diagram for adding, deleting and reading
\item How similarity is calculated
\item Unit testing
\end{itemize}

\subsection{Hybrid Recommender: Weighted}

Returning to the hybrid recommender engine \emph{weighted} which has already been touched on in section \ref{implementation-framework-engine-adapter} and illustrated in Figure \ref{fig:implementation-framework-hybrid-engine-adapter}, this section provides a brief explanation on how the scores are combined by weighting. Weighting in this scenario relates to preferring the results of a  component over the others.

This particular weighted implementation first fetches recommendations from each component recommender engine. The recommendations come with a score attached to it -- a numeric value indicating a level of preference over the other recommendations. The engine has a weight configured as a setting which is preferably a value between 0 and 1 so that the sum of all weights is 1. While looping through each component's recommendations, the score of the recommendation is multiplied with the respective weight for the component (see Figure \ref{fig:implementation-weighted}). This has a dampening effect on the scores. Then, the sets of recommendations are merged into one set. If a recommendation exists in more than one set, then the scores added together. Finally, this merged set is sorted by score in descending order.

\begin{figure}[!ht]
    \begin{tabular}{|
    >{\columncolor[HTML]{ECF4FF}}l |
    >{\columncolor[HTML]{ECF4FF}}r |r|r|r|r|}
    \hline
    \cellcolor[HTML]{BBDAFF}{\color[HTML]{000000} {\bf recommender}} & \multicolumn{1}{c|}{\cellcolor[HTML]{BBDAFF}{\color[HTML]{000000} {\bf weight}}} & \multicolumn{1}{c|}{\cellcolor[HTML]{BBDAFF}{\color[HTML]{000000} {\bf Item \#1}}} & \multicolumn{1}{c|}{\cellcolor[HTML]{BBDAFF}{\color[HTML]{000000} {\bf Item \#2}}} & \multicolumn{1}{c|}{\cellcolor[HTML]{BBDAFF}{\color[HTML]{000000} {\bf Item \#3}}} & \multicolumn{1}{c|}{\cellcolor[HTML]{BBDAFF}{\color[HTML]{000000} {\bf Item \#4}}} \\ \hline
    viewed\_products                                                 & 0.25                                                                             & 1                                                                                & 0.75                                                                             & 0.5                                                                              & 1                                                                                \\ \hline
    wishlisted\_products                                             & 0.75                                                                             & 0.5                                                                              & 0.95                                                                             & 0.3                                                                              & 1                                                                                \\ \hline
    {\bf \it interesting\_products (weighted)}                       & {\bf \it 1}                                                                      & {\bf \it 0.625}                                                                  & {\bf \it 0.9}                                                                    & {\bf \it 0.35}                                                                   & {\bf \it 1}                                                                      \\ \hline
    \end{tabular}
    \caption{Sample Calculation Table of Weighted Hybrid Recommender Engine}
    \label{fig:implementation-weighted}
\end{figure}

\section{Demo Domain System: Magento}

Section \ref{architecture-domain-systems} discussed the definition and characteristics of \emph{domain systems} as systems founded on extensive domain knowledge. Although the focus of the project is on the framework and recommendation engines, it was clear from the beginning that they needed to be trialled and demonstrated on a complex domain system. Since e-commerce websites are amongst the major users of recommender engines, demonstrating the work on an e-commerce system. As proposed, the e-commerce software \emph{Magento} has been used for this. \citet{aheadworks14} analysed \emph{Alexa}'s 1 million top sites index and found that Magento was the leading open-source e-commerce software with a market share of 30 per cent in 2014.

\begin{figure}[!ht]
    \includegraphics[width=\textwidth,center]{screens/basket.png}
    \caption{Content-Based Recommendation Screenshot}
    \label{fig:implementation-magento-basket}
\end{figure}

The authors of Magento are working on a full rewrite of their platform called Magento2 to be released late 2015. This project uses the first release candidate published in March 2015. Albeit Magento2 comes with fundamental technical changes, they do not necessarily make a difference to the purposes of demonstration. Nonetheless the support of the dependency manager \emph{Composer} was principally important to distinct between custom and core code. Secondly, the sample data generator was useful to demo with realistic data.

The source code written for this project is structured as follows:

\begin{description}
    \item[app/code/Koklu/Event] module handles observing and processing of events.
    \item[app/code/Koklu/MasterData] module complements the Event module by handling master data related events and full exports.
    \item[app/code/Koklu/Recommender] modules queries and display recommendations as well as providing a client for the recommendation framework.
    \item[dev/shell/masterdata.php] script runs a full export of master data to the framework.
    \item[lib/internal/Koklu/Rest/Json] fixes a bug in the Zend library which sometimes omits setting the HTTP header \emph{Accept-Encoding} to \emph{JSON}.
\end{description}

\subsection{Events}
\label{implementation-magento-events}

Magento comes with an event subsystem in which observers can subscribe to various events -- from very low-level to very specific functions. This helped to keep the required code clean and short.

The following cases are recorded and posted to the framework as events:

\begin{itemize}
\item \emph{Customer views a product}
\item \emph{Customer adds or removes a product to their wish list}
\item \emph{Customer adds a product to their basket}
\end{itemize}

There are more cases which are interesting in an e-commerce context such as the actual purchase of items. The aforementioned cases have been symbolically chosen as they do not require too many steps to reproduce. By contrast, a checkout on Magento is a longer process which requires documentation and can be time-consuming on slow development environments. Above all, the \emph{In-Common} recommender requires three occurrences of a case to produce a recommendation: the first customer performing a behaviour with another customer doing the same as well as one which the first customer has not experienced yet.

Finally, the customer identification is most of the times part of the event data. A customer who has not logged in yet gets a \emph{visitor ID} assigned to by Magento. This allows behavioural analysis and production of recommendations even for logged out users. Once they log in, the \emph{customer ID} can be used so that the recommendations can source from historic sessions. In order to troubleshoot any issues, all requests and responses to the event API of the framework are logged in a file.

\subsection{Master Data}

The master data is exceptionally important for content-based recommenders as they source their recommendations from similarities between item features. In the Magento context, master data refers to the product catalogue and is sent to the framework as regular events. Again, the event subsystem allows to observer product catalogue changes and notify the framework in real-time. On first run or if explicitly wished, the catalogue data can be exported as a whole with a command-line script. This is known as full export and the data is transmitted in batches.

Magento implements an \emph{entity-attribute-value (EAV)} model. \emph{Entities} are a type of product such as books and phones and are called \emph{attribute sets} in Magento. \emph{Attributes} are fields within a product catalogue and have a value type such as text or numeric amounts. The \emph{values} can be entered freely or chosen from an editable list. The EAV model basically describes that although the number of attributes in a catalogue is vast, only a subset of those are relevant and applicable to an entity -- in practice it means that the attribute \emph{number of pages} is relevant for a book but not for a phone.

\begin{figure}[!ht]
    \includegraphics[width=\textwidth,center]{screens/masterdata.png}
    \caption{Master Data Management Screenshot}
    \label{fig:implementation-magento-master-data}
\end{figure}

Magento provides a user interface to manage these attributes and attribute sets; thus means that the master data can vary extensively between Magento instances. There are \emph{system attributes} which remain the same on any Magento instance but the majority of the relevant data would be merchant-specific. To accommodate this, the demo project implements a way for the merchant to mark attributes as \emph{Used in Recommender} which are to be exported to the framework, as shown in figure \ref{fig:implementation-magento-master-data}. However, as the demo project relies on the sample data generator of Magento to create attributes, setting that mark had to happen dynamically. The sample data generator and its static source data known as \emph{fixtures} have been extended so that a fixture can be replaced by a customised version.

\subsection{Recommendations}

The integration of recommendations has been implemented in three parts:

First, a thin \emph{client} has been written which performs the request and processes the responses to the recommendation API of the framework. All requests and responses are logged in a file for troubleshooting.

Second, a \emph{recommendation model} is implemented for each recommendation configured in the framework such as \emph{viewed products} and \emph{similar items in basket}. The purpose of these model classes is to provide the IDs the recommendation should be based on -- e.g. current user ID for the \emph{viewed products} and product IDs in the basket for \emph{similar items in the basket}. This is based on the requirement that each recommendation is in relation to something. They do not know internals of how the recommendations work. They are derived from an abstract class, which reduces the code size of the individual model classes to a minimum. They return a product collection filtered by the product IDs from the recommendation response.

Third, a \emph{recommendation widget} is provided which handles the display of recommendations to the user. Magento widgets are re-usable, configurable blocks which can be placed on the website. The demo project makes use of a universal product listing widget and feeds it with the product collection provided by the recommendation class. Magento enables developers and merchants to customise the layout of their website in a flexible way. The demo project was able to place these widgets on existing page by supplying short XML files. An exception is the widget on the homepage (seen in figure \ref{fig:implementation-magento-homepage}) as that page is managed by the \emph{content management (sub)system (CMS)} of Magento. Since the homepage is part of the sample data, a customised fixture has been provided, as discussed in the previous section.

\begin{figure}[!ht]
    \includegraphics[width=\textwidth,center]{screens/homepage.png}
    \caption{Homepage Recommendations Screenshot}
    \label{fig:implementation-magento-homepage}
\end{figure}

\section{Provisioning}

Provisioning refers to the process of preparing an environment which fulfills the requirements to run systems and applications. It involves the installation of languages and libraries as well as proper configuration.

This project relies on the \emph{Linux} operating system and comes with provisioning instructions, which are outlined in the next sections.

\subsection{Virtualisation with Vagrant}

\emph{Vagrant} is software that manages virtual environments -- emulated computer systems also known as \emph{virtual machines} -- for development purposes. It enables a development team to standardise their development environments. This is in particular useful when the computer systems of developers vary from the computer system of the development environment -- e.g. a developer on \emph{Windows} working on a software running on Linux -- or among each other -- i.e. developers using different computer systems which would require provisioning instructions for all computer systems used. In order to run Vagrant, a single configuration file called \emph{Vagrantfile} written in \emph{Ruby} is added to the project's \emph{version control system} such as \emph{Git} and therefore shared with the team.

Vagrant does not do the virtualisation itself but relies on established virtualisation software such as \emph{VirtualBox} and \emph{VMWare}. It also relies on so called \emph{boxes} -- a bare bone installation of a computer system minimally configured for Vagrant -- to bootstrap the virtual machine. Although the project works on any Linux distribution, due to the box requirement of Vagrant the Linux distribution \emph{Ubuntu} (version 14.04) has been used.

Another challenge was the fact that the sample data generator of \emph{Magento} is very inefficient and takes a few hours to complete. In order to reduce the provisioning time to a minimum, it was then decided to package a fully provisioned version of the development environment to a ready-to-go box. \emph{HashiCorp} -- the authors of Vagrant -- provide a service called \emph{Atlas} which allows such boxes to be uploaded and available publicly. Boxes for VirtualBox and VMWare have been uploaded to Atlas since Vagrant boxes are specific to the virtualisation software used. It is rather important to notice that VMWare as well as its Vagrant provider -- the middleware between Vagrant and VMWare -- are both commercial whereas VirtualBox is open-source and free.

Vagrant also provides native support for configuration management software as discussed in the next section.

\subsection{Configuration Management with Puppet}

\emph{Puppet} is open-source software which manages the configuration of \emph{Microsoft Windows}, Linux and other \emph{Unix}-like systems such as \emph{Mac OS X}. This is achieved by describing the expected system configuration in so-called \emph{manifest} files written in a custom declarative language derived from \emph{Ruby}. Upon execution, Puppet interprets these manifests into a configuration catalogue and compares it against the configuration of one or more new or existing systems. Differences noticed during that step are corrected by Puppet. This ensures the expected configuration on those systems and can be called repetitively.

Puppet supports writing manifests for more than one target environment. In fact, most companies are using Puppet to ensure the same configuration (with some variables) on multiple environments such as production, staging and development. In the Vagrant context the Puppet provisioning is called by default when a new virtual machine is created. However, it can also be called explicitly. Since this project utilises Puppet to provision a development environment only, the manifests are not ready for production. Ensuring that essential security measures amongst others changing default passwords were beyond the scope of this project.

Manifests can be grouped into so called Puppet \emph{modules}. \emph{PuppetLabs} -- the authors of Puppet - operate a community called \emph{PuppetForge} where modules are shared. This project utilised \emph{PuppetForge} modules e.g. for \emph{Apache} and \emph{PHP} where possible. In reality, most such modules are officially authored by PuppetLabs. Nonetheless, not all modules covered all the configuration needs of this project and were thus custom written inter alia for \emph{Magento}, \emph{Neo4j} as well as the \emph{framework} and \emph{recommendation engines}. The Magento module builds dependencies, creates an Apache virtual host and a MySQL database and runs the Magento installer. The Neo4j module installs and configures the Neo4j server. The recommender module configures both framework and two recommendation engines. It creates Apache virtual hosts, installs dependencies, creates \emph{supervisord} programs to manage background processes and sets up \emph{Celery} and \emph{Flower}. External modules are integrated as Git \emph{submodules}. The provisioning source code in \ref{appendix-soure-code-provisioning} only lists manifests written by the project author.

Puppet can be understood as part of the \emph{infrastructure as code} or \emph{programmable infrastructure} initiatives in organisations. It enables version controlling and automation of provisioning infrastructure. Especially infrastructure based on \emph{cloud computing} and \emph{platform as a service (PaaS)} which involve many but constantly changing (e.g. auto-scaling) systems benefit from this. Alternatives to Puppet are \emph{Chef}, \emph{SaltStack} and \emph{Ansible}.

\subsection{Dependency Management}

Dependency management supports the declaration and installation of libraries a software system depends on. Whereas system package managers like \emph{Yum} and \emph{Apt} provide a system-wide solution for packages, dependency managers support versioned solution on a per-project basis. The latter is important as two pieces of software may depend on different versions of a dependency. Furthermore, dependency managers are usually tailored for a programming language and allow the distribution of libraries, which may not be available as a Yum or Apt package.

As mentioned in the abstract, this work relies on many open-source projects. It was since particularly important to separate own work from those third-party projects. For this, dependency managers were very essential. The \emph{framework} relies on the Python dependency manager \emph{pip}. The \emph{item-similarity} engine as well as the demo application \emph{Magento} use the PHP dependency manager \emph{Composer}. Finally, the \emph{in-common} engine utilises \emph{gom} which adds per-project capabilities to the overall self-sufficient \emph{Go} dependency manager.