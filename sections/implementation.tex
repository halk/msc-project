\chapter{Implementation \& Testing}

This chapter not only discusses the technological details of this project but also introduces concrete implementations of two recommender systems as well as one domain system.

From the very start of this project, it was planned to use free and open-source technologies -- from database management systems to re-usable software libraries. Beside being a well-established best practice in the software programming, the main motivation for this is to avoid software code which is trivial and not contributing to the objectives of the project. It would have gone beyond the scope of this project to build everything from scratch. In fact, by using open-source technology the resulting software code has become very compact and readable.

\section{Framework}

The framework has been written in \emph{Python} and is entirely object-oriented. The source code is grouped into modules. The directory structure is as follows:

\begin{description}
    \item[api] implements the \emph{application programming interface (API)}
    \item[config] holds the configuration file as well as the XML schema definition.
    \item[core] provides classes processing the configuration file as well as taxonomies. Furthermore, the engine submodule implements abstract base classes for engine adapters.
    \item[engines] contains engine adapter classes. In this case, it has adapters for the engines \emph{in-common}, \emph{item-similarity} and the hybrid engine \emph{weighted}.
    \item[log] has log files which are useful to troubleshoot problems.
    \item[tests] defines a unit test suite.
    \item[worker] implements the workers for Event and Recommend
    \item[api.wsgi] is the WSGI server loaded by Apache and runs the API.
    \item[config.py] loads the configuration and makes it available for other classes in the source code.
    \item[monitor.py] reloads the WSGI server when local changes to Python files were detected. The author of this particular file has been acknowledged in the source code.
    \item[requirements.txt] holds the name and versions of Python libraries the framework is depending on. It is used by the Python dependency manager \emph{pip}.
\end{description}

The framework has no persistence at all and thus does not utilise a database management system. As mentioned in the section \ref{architecture-framework}, it operates as middleware between domain and recommender systems, therefore relying on those to handle their persistence requirements. as far as the framework is concerned, there is no need or purpose to persist data.

\subsection{API}

The \emph{application programming interface (API)} of the framework is based on the popular, so-called micro web application framework \emph{Flask}. The notation of micro refers to the fact, that Flask is very minimal and has almost no constraints on other technologies such as database management systems.

Although Flask is RESTful compliant by default, the Flask extension \emph{Flask-RESTful} was used in this project. Where Flask associates a call back to a route such as \texttt{/event}, Flask-RESTful associates a resource class and method e.g. Event and \emph{post} to the route (Figure \ref{fig:implementation-framework-api-event}).

\begin{figure}[ht]
    \inputminted{py}{./includes/source/framework/api/event.py}
    \caption{Framework: Event API}
    \label{fig:implementation-framework-api-event}
\end{figure}

Additionally, the API makes use of the \emph{Blueprint} feature of Flask which allows the implementation of independent APIs and its subscription to the main API with a prefix (Figure \ref{fig:implementation-framework-api}).

\begin{figure}[ht!]
    \begin{minted}{python}
from flask import Flask
from config import config

# setting up flask
app = Flask(__name__)
celery = config.get_celery('worker')

# setting up logging
# [...]

# registering submodules
from api.event import event
from api.recommend import recommend

app.register_blueprint(event, url_prefix='/event')
app.register_blueprint(recommend, url_prefix='/recommend')

# default route

@app.route("/")
def hello():
    return "Welcome to the Multi-Purpose Recommender Framework!"
    \end{minted}
    \caption{Framework: API}
    \label{fig:implementation-framework-api}
\end{figure}

The API uses the \emph{JavaScript Object Notation (JSON)} format data and is served by the open-source web server \emph{Apache} as a virtual host through the \emph{web server gateway interface (WSGI)} and listens to requests at \texttt{api.msc.koklu.me}.

It was originally proposed to use \emph{NodeJS} and \emph{express} for the API. However it was chosen to use Python for the following reasons. First, the rest of the framework was going to be in Python and the task queue management software \emph{Celery}, which is going to be introduced in the next section, is working most elegantly with Python. Second, there was no exclusive benefit by implementing the API in NodeJS. Third, Flask provides the same minimalistic approach to defining routes as express.

\subsection{Worker \& Task Queue}

The project relies on the task queue \emph{Celery} to establish an asynchronous and selectively synchronous communication between the API and workers. Celery is written in Python and supports multiple brokers such as \emph{RabbitMQ} and \emph{Beanstalk}. Former is used as broker in this project. The Event API is calling its worker asynchronously -- thus not waiting for a response (queue \& forget) -- whereas the Recommend API is doing that synchronously. Figure \ref{fig:implementation-framework-worker} lists the source code of the event worker which is upon request going through all observers subscribed to the given event and calls the configured event method on the engine adapter.

\begin{figure}[ht]
    \inputminted{py}{./includes/source/framework/worker/event.py}
    \caption{Framework: Event Worker}
    \label{fig:implementation-framework-worker}
\end{figure}

It was initially intended to use RabbitMQ natively as a message bus implementing the \emph{advanced message queuing protocol (AMQP)}. However, while looking for RabbitMQ client libraries and elegant ways to manage the overhad of using message buses for distributing tasks, Celery came up which abstracts that complexity completely. Tasks can be run as if they are a regular method in the source code (see Figure \ref{fig:implementation-framework-api-event}).

Flower is an administrative interface for Celery providing a real-time monitor and can be accessed at \texttt{http://flower.msc.koklu.me} (Figure \ref{fig:implementation-framework-flower}).

\begin{figure}[ht]
    \includegraphics[width=\textwidth,center]{screens/flower.png}
    \caption{Administrative Interface Flower for Celery}
    \label{fig:implementation-framework-flower}
\end{figure}

\subsection{Configuration}

\begin{figure}[ht!]
    \begin{minted}{xml}
<?xml version="1.0" encoding="UTF-8"?>
<config xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:noNamespaceSchemaLocation="./config.xsd">
    <recommenders>
        <!-- [...] -->
        <recommender name="similar_products_in_basket" engine="item_similarity">
            <on event="saved_product" do="post" />
            <on event="deleted_product" do="delete" />
            <taxonomy inherit="base">
                <taxon name="item_id">sku</taxon>
                <taxon name="itemIds">sku</taxon>
                <taxon name="attributes">data</taxon>
            </taxonomy>
        </recommender>
        <hybrid_recommender name="interesting_products" engine="weighted">
            <components>
                <component name="views" recommender="common_products_viewed" />
                <component name="wishlists" recommender="common_products_wishlisted" />
            </components>
            <settings>
                <weight>
                    <views>0.25</views>
                    <wishlists>0.75</wishlists>
                </weight>
            </settings>
        </hybrid_recommender>
    </recommenders>
    <taxonomies>
        <taxonomy name="base">
            <taxon name="limit">limit</taxon>
        </taxonomy>
        <!-- [...] -->
    </taxonomies>
    <engines>
        <engine name="in_common">
            <settings>
                <base_url>http://localhost:8080/</base_url>
            </settings>
        </engine>
        <!-- [...] -->
    </engines>
    <settings>
        <celery>
            <broker>amqp://framework:framework@localhost:5672/framework</broker>
            <backend>redis://localhost</backend>
        </celery>
    </settings>
</config>
    \end{minted}
    \caption{Framework: Shortened XML configuration}
    \label{fig:implementation-framework-configuration}
\end{figure}

Figure \ref{fig:implementation-framework-configuration} shows a shortened configuration file of the framework and is explained as follows:

\begin{description}
    \item[recommenders/recommender] defines a recommender by name and the engine to be used. Furthermore it has a list of events it subscribes to (\texttt{on}) where the \texttt{do} attribute refers to the method of the engine adapter to be called when the event occurs. A recommender also defines a taxonomy which usually inherits from a global taxonomy.
    \item[recommenders/hybrid_recommender] defines a hybrid recommender which consists of two or more components. It may also have some settings which can be accessed by the engine adapter.
    \item[taxonomies/taxonomoy] defines a global taxonomy which is a terminology mapper between domain and recommender systems. It may inherit from another taxonomy. A taxonomy consists of taxon elements which describe a single mapping.
    \item[engines/engine] holds settings for engines.
    \item[settings] hold global settings of the framework such as connection details for Celery.
\end{description}

The project also provides an \emph{XML schema definition (XSD)} which can be used to validate a framework configuration.

\subsection{Engine Adapters}

\emph{Engine adapters} are thin clients to recommender engines. The formal requirement is that they implement a \texttt{recommend} method as well as methods used in event subscriptions. Other than that it is completely flexible in how the engine is called. For convenience, the abstract base class provides a RESTful skeleton which is used by the engine adapters implemented in this project such as the \emph{item-similarity} adapter (see Figure \ref{fig:implementation-framework-engine-adapter}). Engine adapters have access to engine settings defined in the configuration file such as a \emph{uniform resource locator (URL)}.

\begin{figure}[!ht]
    \inputminted{py}{./includes/source/framework/engines/item\string_similarity.py}
    \caption{Framework: Item-Similarity Engine Adapter}
    \label{fig:implementation-framework-engine-adapter}
\end{figure}

Engine adapters for hybrid engines are more than just thin clients. Their formal requirement is to implement a \texttt{recommend} method without any event methods. In this method they have full flexibility on how to make use of the components. Figure \ref{fig:implementation-framework-hybrid-engine-adapter} shows the implementation of the \emph{weighted} hybrid engine adapter.

\begin{figure}[!ht]
    \begin{minted}{py}
from collections import OrderedDict
from core.engine.hybrid import HybridEngine as ParentHybridEngine

class HybridEngine(ParentHybridEngine):
    def recommend(self, body):
        return self.merge(self.apply_weight(self.get_results(body)))

    def get_results(self, body):
        results = {}
        for name, component in self.components.iteritems():
            result = component.recommend(body, True)
            if result:
                results[name] = result

        return results

    # [...] implementations of merge and apply_weight
    \end{minted}
    \caption{Framework: Weighted Hybrid Engine Adapter}
    \label{fig:implementation-framework-hybrid-engine-adapter}
\end{figure}

\subsection{Testing}

The implementation of the framework makes extensive use of automated \emph{unit tests}. Unit testing is a software testing method which validates the correctness and executability pieces of software code (\emph{units}) such as functions, methods and classes. In fact, the 39 unit tests provided have a code coverage of one hundred per cent which means that every line of code is passed during one or more unit tests. These unit tests are testing the API, the validity of the XML configuration, core classes, engine adapters as well as workers. A separate XML configuration file is also included which makes sure that some rarer edge cases are tested as well.

The project utilises \emph{nosetests} to run the tests. Furthermore, the \emph{Software as a Service (SaaS)} platform \emph{Travis CI} is used to build a virtual environment and call nosetests everytime the framework code has been changed (pushed into the \emph{GitHub} repository). This is also known as \emph{continuous integration (CI)}. Finally, the SaaS Scrutinizer is integrated to process the code coverage reports generated by Travis CI.

\section{Engines}

\subsection{Collaborative Recommender: In Common}

\emph{Status: Not Started}

\begin{itemize}
\item Collaborative filtering
\item Real-time
\item Data and domain agnostic
\item Based on Go
\item API
\item Based on graphical databases and nodes
\item Figure to show diagram for adding, deleting and reading
\item Unit testing
\end{itemize}

\subsection{Content-Based Recommender: Item Similarity}

\emph{Status: Not Started}

\begin{itemize}
\item Content-based filtering
\item Silex, MongoDB, Doctrine ODM
\item Requires master data
\item Show diagram for adding, deleting and reading
\item How similarity is calculated
\item Unit testing
\end{itemize}

\subsection{Hybrid Recommender: Weighted}

\emph{Status: Not Started}

\begin{itemize}
\item Weight
\item No specific implementation, assisting methods to access components, rest job of the adapter
\end{itemize}

\section{Demo Domain System: Magento}

Section \ref{architecture-domain-systems} discussed the definition and characteristics of \emph{domain systems} as systems founded on extensive domain knowledge. Although the focus of the project is on the framework and recommendation engines, it was clear from the beginning that they needed to be trialled and demonstrated on a complex domain system. Since e-commerce websites are amongst the major users of recommender systems, demonstrating the work on an e-commerce system. As proposed, the e-commerce software \emph{Magento} has been used for this. \citet{aheadworks14} analysed \emph{Alexa}'s 1 million top sites index and found that Magento was the leading open-source e-commerce software with a market share of 30 per cent in 2014.

\begin{figure}[!ht]
    \includegraphics[width=\textwidth,center]{screens/basket.png}
    \caption{Content-based recommendations on shopping basket}
    \label{fig:implementation-magento-basket}
\end{figure}

The authors of Magento are working on a full rewrite of their platform called Magento2 to be released late 2015. This project uses the first release candidate published in March 2015. Albeit Magento2 comes with fundamental technical changes, they do not necessarily make a difference to the purposes of demonstration. Nonetheless the support of the dependency manager \emph{Composer} was principally important to distinct between custom and core code. Secondly, the sample data generator was useful to demo with realistic data.

The source code written for this project is structured as follows:

\begin{description}
    \item[app/code/Koklu/Event] module handles observing and processing of events.
    \item[app/code/Koklu/MasterData] module complements the Event module by handling master data related events and full exports.
    \item[app/code/Koklu/Recommender] modules queries and display recommendations as well as providing a client for the recommendation framework.
    \item[dev/shell/masterdata.php] script runs a full export of master data to the framework.
    \item[lib/internal/Koklu/Rest/Json] fixes a bug in the Zend library which sometimes omits setting the HTTP header \emph{Accept-Encoding} to \emph{JSON}.
\end{description}

\subsection{Events}
\label{implementation-magento-events}

Magento comes with an event subsystem in which observers can subscribe to various events -- from very low-level to very specific functions. This helped to keep the required code clean and short.

The following cases are recorded and posted to the framework as events:

\begin{itemize}
\item \emph{Customer views a product}
\item \emph{Customer adds or removes a product to their wish list}
\item \emph{Customer adds a product to their basket}
\end{itemize}

There are more cases which are interesting in an e-commerce context such as the actual purchase of items. The aforementioned cases have been symbolically chosen as they do not require too many steps to reproduce. In contrary, a checkout on Magento is a longer process which requires documentation and can be time-consuming on slow development environments. Above all, the \emph{In-Common} recommender requires three occurrences of a case to produce a recommendation: the first customer performing a behaviour with another customer doing the same as well as one which the first customer has not experienced yet.

Finally, the customer identification is most of the times part of the event data. A customer who has not logged in yet gets a \emph{visitor ID} assigned to by Magento. This allows behavioural analysis and production of recommendations even for logged out users. Once they log in, the \emph{customer ID} can be used so that the recommendations can source from historic sessions. In order to troubleshoot any issues, all requests and responses to the event API of the framework are logged in a file.

\subsection{Master Data}

The master data is exceptionally important for content-based recommenders as they source their recommendations from similarities between item features. In the Magento context, master data refers to the product catalogue and is sent to the framework as regular events. Again, the event subsystem allows to observer product catalogue changes and notify the framework in real-time. On first run or if explicitly wished, the catalogue data can be exported as a whole with a command-line script. This is known as full export and the data is transmitted in batches.

Magento implements an \emph{entity-attribute-value (EAV)} model. \emph{Entities} are a type of product such as books and phones and are called \emph{attribute sets} in Magento. \emph{Attributes} are fields within a product catalogue and have a value type such as text or numeric amounts. The \emph{values} can be entered freely or chosen from an editable list. The EAV model basically describes that although the number of attributes in a catalogue is vast, only a subset of those are relevant and applicable to an entity -- in practice it means that the attribute \emph{number of pages} is relevant for a book but not for a phone.

\begin{figure}[!ht]
    \includegraphics[width=\textwidth,center]{screens/masterdata.png}
    \caption{Manage Master Data in the Back Office of Magento}
    \label{fig:implementation-magento-master-data}
\end{figure}

Magento provides a user interface in the back office to manage these attributes and attribute sets; thus means that the master data can vary extensively between Magento instances. There are so-called \emph{system attributes} which remain the same on any Magento instance but the majority of the relevant data would be merchant-specific. To accommodate this, the demo project implements a way for the merchant to mark attributes as \emph{Used in Recommender} which are to be exported to the framework, as shown in figure \ref{fig:implementation-magento-master-data}. However, as the demo project relies on the sample data generator of Magento to create attributes, setting that mark had to happen dynamically. The sample data generator and its static source data known as \emph{fixtures} have been extended so that a fixture can be replaced by a customised version.

\subsection{Recommendations}

The integration of recommendations has been implemented in three parts:

First, a thin \emph{client} has been written which performs the request and processes the responses to the recommendation API of the framework. All requests and responses are logged in a file for troubleshooting.

Second, a \emph{recommendation model} is implemented for each recommendation configured in the framework such as \emph{viewed products} and \emph{similar items in basket}. The purpose of these model classes is to provide the IDs the recommendation should be based on -- e.g. current user ID for the \emph{viewed products} and product IDs in the basket for \emph{similar items in the basket}. This is based on the requirement that each recommendation is in relation to something. They do not know internals of how the recommendations work. They are derived from an abstract class, which reduces the code size of the individual model classes to a minimum. They return a product collection filtered by the product IDs from the recommendation response.

Third, a \emph{recommendation widget} is provided which handles the display of recommendations to the user. Magento widgets are re-usable, configurable blocks which can be placed on the website. The demo project makes use of a universal product listing widget and feeds it with the product collection provided by the recommendation class. Magento enables developers and merchants to customise the layout of their website in a flexible way. The demo project was able to place these widgets on existing page by supplying short XML files. An exception is the widget on the homepage (seen in figure \ref{fig:implementation-magento-homepage}) as that page is managed by the \emph{content management (sub)system (CMS)} of Magento. Since the homepage is part of the sample data, a customised fixture has been provided, as discussed in the previous section.

\begin{figure}[!ht]
    \includegraphics[width=\textwidth,center]{screens/homepage.png}
    \caption{Recommendations on the homepage}
    \label{fig:implementation-magento-homepage}
\end{figure}

\section{Provisioning}

Provisioning refers to the process of preparing an environment which fulfills the requirements to run systems and applications. It involves the installation of languages and libraries as well as proper configuration.

This project relies on the \emph{Linux} operating system and comes with provisioning instructions, which are outlined in the next sections.

\subsection{Virtualisation with Vagrant}

\emph{Vagrant} is software that manages virtual environments -- emulated computer systems also known as \emph{virtual machines} -- for development purposes. It enables a development team to standardise their development environments. This is in particular useful when the computer systems of developers vary from the computer system of the development environment -- e.g. a developer on \emph{Windows} working on a software running on Linux -- or among each other -- i.e. developers using different computer systems which would require provisioning instructions for all computer systems used. In order to run Vagrant, a single configuration file called \emph{Vagrantfile} written in \emph{Ruby} is added to the project's \emph{version control system} such as \emph{Git} and therefore shared with the team.

Vagrant does not do the virtualisation itself but relies on established virtualisation software such as \emph{VirtualBox} and \emph{VMWare}. It also relies on so called \emph{boxes} -- a bare bone installation of a computer system minimally configured for Vagrant -- to bootstrap the virtual machine. Although the project works on any Linux distribution, due to the box requirement of Vagrant the Linux distribution \emph{Ubuntu} (version 14.04) has been used.

Another challenge was the fact that the provisioning instruction calling the sample data generation of \emph{Magento} took so long to an extent that it was unbearable for the project demonstration. It was then decided to package a fully provisioned version of the development environment to a ready-to-go box. \emph{HashiCorp} -- the authors of Vagrant -- provide a service called \emph{Atlas} which allows such boxes to be uploaded and available publicly. Boxes for VirtualBox and VMWare have been uploaded to Atlas since Vagrant boxes are specific to the virtualisation software used. It is rather important to notice that VMWare as well as its Vagrant provider -- the middleware between Vagrant and VMWare -- are both commercial whereas VirtualBox is open-source and free.

Vagrant also provides native support for configuration management software as discussed in the next section.

\subsection{Configuration Management with Puppet}

\emph{Puppet} is open-source software which manages the configuration of \emph{Microsoft Windows}, Linux and other \emph{Unix}-like systems such as \emph{Mac OS X}. This is achieved by describing the expected system configuration in so-called \emph{manifest} files written in a custom declarative language derived from \emph{Ruby}. Upon execution, Puppet interprets these manifests into a configuration catalogue and compares it against the configuration of one or more new or existing systems. Differences noticed during that step are corrected by Puppet. This ensures the expected configuration on those systems and can be called repetitively.

Puppet supports writing manifests for more than one target environment. In fact, most companies are using Puppet to ensure the same configuration (with some variables) on multiple environments such as production, staging and development. In the Vagrant context the Puppet provisioning is called by default when a new virtual machine is created. However, it can also be called explicitly. Since this project utilises Puppet to provision a development environment only, the manifests are not ready for production. Ensuring that essential security measures amongst others changing default passwords were go beyond the scope of this project.

Manifests can be grouped into so called Puppet \emph{modules}. \emph{PuppetLabs} -- the authors of Puppet - operate a community called \emph{PuppetForge} where modules are shared. This project utilised \emph{PuppetForge} modules e.g. for \emph{Apache} and \emph{PHP} where possible. In reality, most such modules are officially authored by PuppetLabs. Nonetheless, not all modules covered all the configuration needs of this project and were thus custom written inter alia for \emph{Magento}, \emph{Neo4j} as well as the \emph{framework} and \emph{recommendation engines}. The Magento module builds dependencies, creates an Apache virtual host and a MySQL database and runs the Magento installer. The Neo4j module installs and configures the Neo4j server. The recommender module configures both framework and two recommendation engines. It creates Apache virtual hosts, installs dependencies, creates \emph{supervisord} programs to manage background processes and sets up \emph{Celery} and \emph{Flower}. External modules are integrated as Git \emph{submodules}. The provisioning source code in \ref{appendix-soure-code-provisioning} only lists manifests written by the project author.

Puppet can be understood as part of the \emph{infrastructure as code} or \emph{programmable infrastructure} initiatives in organisations. It enables version controlling and automation of provisioning infrastructure. Especially infrastructure based on \emph{cloud computing} and \emph{platform as a service (PaaS)} which involve many but constantly changing (e.g. auto-scaling) systems benefit from this. Alternatives to Puppet are \emph{Chef}, \emph{SaltStack} and \emph{Ansible}.

\subsection{Dependency Management}

Dependency management supports the declaration and installation of libraries a software depends on. Whereas system package managers like \emph{Yum} and \emph{Apt} provide a system-wide solution for packages, dependency managers support versioned solution on a per-project basis. Latter is important as two pieces of software may depend on different versions of a dependency. Furthermore, dependency managers are usually tailored for a programming language and allow the distribution of libraries, which may not be available as a Yum or Apt package.

As mentioned in the abstract, this work relies on many open-source projects. It was since particularly important to separate own work from those third-party projects. For this, dependency managers were very essential. The \emph{framework} relies on the Python dependency manager \emph{pip}. The \emph{item-similarity} engine as well as the demo application \emph{Magento} use the PHP dependency manager \emph{Composer}. Finally, the \emph{in-common} engine utilises \emph{gom} which adds per-project capabilities to the overall self-sufficient \emph{Go} dependency manager.